{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHA535/Marketing_Automations_Notebooks_With_GPT/blob/main/Automatic_Newsjacking_Ideation_and_Trend_Analysis_(Public).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3TtyjflEtOu"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install google-search-results\n",
        "!pip install newspaper3k\n",
        "!pip install sentence-transformers\n",
        "!pip install sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Load API key from environment variable (ensure you've set this in your environment)\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')# Ensure your API key is set in your environment\n",
        "\n",
        "# Define the GPT model name\n",
        "MODEL_NAME = \"gpt-4\"\n",
        "\n",
        "def generate_text(prompt):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            model=MODEL_NAME,\n",
        "            prompt=prompt,\n",
        "            max_tokens=1500,\n",
        "            temperature=0.6,\n",
        "            n=1,\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except openai.OpenAIError as e:\n",
        "        print(f\"OpenAI API error: {e}\")\n",
        "        return \"\"  # Return an empty string if an error occurs\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def generate_subtopics(topic):\n",
        "    prompt = f\"Generate 40 common subtopics related to {topic}\"\n",
        "    return generate_text(prompt).split(\"\\n\")\n",
        "\n",
        "def generate_subsubtopics(subtopic):\n",
        "    prompt = f\"Generate 20 common subsubtopics related to {subtopic}\"\n",
        "    return generate_text(prompt).split(\"\\n\")\n",
        "\n",
        "def generate_questions(topic, subtopic, subsubtopic):\n",
        "    prompt = f\"\"\"You are an all-knowing AI that specializes in search behavior, SEO, and search intent.\n",
        "    You are especially good at predicting questions related to topics.\n",
        "    Please generate 30 of the most common questions related to {subsubtopic}\n",
        "    within the context of {subtopic} in the larger topic of {topic}.\"\"\"\n",
        "\n",
        "    questions = generate_text(prompt).split(\"\\n\")\n",
        "    return [question.split(\". \")[-1] for question in questions if question.strip()]\n",
        "\n",
        "def process_subsubtopic(topic, subtopic, subsubtopic):\n",
        "    questions = generate_questions(topic, subtopic, subsubtopic)\n",
        "    data = {\n",
        "        \"topic\": topic,\n",
        "        \"subtopic\": subtopic,\n",
        "        \"subsubtopic\": subsubtopic,\n",
        "    }\n",
        "    for i, question in enumerate(questions):\n",
        "        data[f\"Question {i + 1}\"] = question\n",
        "    return data\n",
        "\n",
        "def main(topic):\n",
        "    # Generate subtopics\n",
        "    subtopics = generate_subtopics(topic)\n",
        "    data = []\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:  # Limiting to 5 concurrent threads\n",
        "        futures = []\n",
        "\n",
        "        # Generate subsubtopics and process questions in parallel\n",
        "        for subtopic in subtopics:\n",
        "            subsubtopics = generate_subsubtopics(subtopic)\n",
        "            for subsubtopic in subsubtopics:\n",
        "                futures.append(executor.submit(process_subsubtopic, topic, subtopic, subsubtopic))\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            data.append(future.result())\n",
        "\n",
        "    # Convert the collected data to a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    topic = \"Rehan Centers\"\n",
        "    df = main(topic)\n",
        "    print(df)\n"
      ],
      "metadata": {
        "id": "Zf6ABC0EAhhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_df.to_csv('text.csv')"
      ],
      "metadata": {
        "id": "-2vdNG7cHzuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}